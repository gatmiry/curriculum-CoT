================================================================================
Using device: cuda
samples type in get_batch is torch.int64
bacth type before return is torch.int64
batch type is torch.int64
shape of self.transformer.wte(idx) torch.Size([128, 12, 64])  shape of cts_tokens torch.Size([128, 36])
Error executing job with overrides: []
Traceback (most recent call last):
  File "/accounts/projects/peter/gatmiry/distributional-CoT/train.py", line 47, in main
    train.fit()
    ~~~~~~~~~^^
  File "/accounts/projects/peter/gatmiry/distributional-CoT/test_composite_function.py", line 63, in fit
    output_vals, loss = model(batch, cot_outputs)
                        ~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/accounts/projects/peter/gatmiry/distributional-CoT/model.py", line 101, in forward
    x = pe_vecs + torch.cat([self.transformer.wte(idx), cts_tokens.unsqueeze(2) @ self.wte[1].unsqueeze(0).unsqueeze(0)], dim=1)
                                                                                  ^^^^^^^^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1928, in __getattr__
    raise AttributeError(
        f"'{type(self).__name__}' object has no attribute '{name}'"
    )
AttributeError: 'GPT' object has no attribute 'wte'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
