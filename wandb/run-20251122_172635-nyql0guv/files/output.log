================================================================================
Using device: cuda
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([0.1620, 0.0145, 0.0102], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 0 Loss: 1.4958715438842773 Final Loss: 0.8281170725822449
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([-0.0089,  0.1328,  1.1417], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 100 Loss: 0.028627505525946617 Final Loss: 2.411440372467041
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([-0.0084,  0.0585,  1.0186], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 200 Loss: 0.0011138870613649487 Final Loss: 2.853267192840576
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([1.9943, 1.9976, 0.9937], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 300 Loss: 0.0003425485920161009 Final Loss: 2.6656341552734375
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0022, -1.9917,  0.9920], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 400 Loss: 0.00016008706006687135 Final Loss: 2.6127543449401855
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([1.9992, 2.0006, 0.9967], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 500 Loss: 8.297873137053102e-05 Final Loss: 2.93343448638916
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([1.9997, 1.9997, 0.9961], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 600 Loss: 4.1891977161867544e-05 Final Loss: 2.683969020843506
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-6.2694e-03, -1.4899e-04,  1.0043e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 700 Loss: 3.5762386687565595e-05 Final Loss: 3.122182846069336
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([-0.0045,  0.0143,  1.0009], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 800 Loss: 2.1182113414397463e-05 Final Loss: 2.9386518001556396
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 1.9998, 1.0019], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 900 Loss: 1.3950446373200975e-05 Final Loss: 2.8732340335845947
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([1.9998, 2.0000, 1.0016], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 1000 Loss: 5.498069640452741e-06 Final Loss: 3.500382423400879
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([ 0.0013, -0.0025,  1.0005], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 1100 Loss: 6.676251359749585e-06 Final Loss: 2.8106842041015625
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-6.0322e-03, -5.9091e-04,  9.9995e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 1200 Loss: 8.050014912441839e-06 Final Loss: 3.125013828277588
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0016, -2.0005,  1.0005], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 1300 Loss: 4.5373308239504695e-06 Final Loss: 2.751244306564331
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0004], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 1400 Loss: 2.1460857624333585e-06 Final Loss: 3.312930107116699
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0001, -2.0002,  0.9996], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 1500 Loss: 1.4408026345336111e-06 Final Loss: 3.2504687309265137
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-7.6465e-04, -1.1525e-03,  9.9992e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 1600 Loss: 1.7177570725834812e-06 Final Loss: 2.56209659576416
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([ 1.1391e-03, -4.4695e-04,  1.0016e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 1700 Loss: 1.3815631518809823e-06 Final Loss: 2.9374022483825684
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0001, 1.9998, 1.0009], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 1800 Loss: 2.3482984033762477e-05 Final Loss: 2.688664436340332
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([-0.0032, -0.0013,  0.9999], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 1900 Loss: 3.1735758057038765e-06 Final Loss: 3.0631136894226074
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -1.9999,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 2000 Loss: 9.309635515819537e-07 Final Loss: 2.5622854232788086
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([ 1.7364e-04, -1.5302e-03,  9.9994e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 2100 Loss: 6.359607027661696e-07 Final Loss: 3.7495222091674805
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0001], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 2200 Loss: 5.104786851006793e-07 Final Loss: 2.9377357959747314
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-2.7561e-04, -1.3911e-03,  9.9993e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 2300 Loss: 4.236845541072398e-07 Final Loss: 3.1874775886535645
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([-3.5880e-04,  1.9287e-03,  9.9977e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 2400 Loss: 4.0489143771083036e-07 Final Loss: 3.062572717666626
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([-2.7080e-04,  9.5738e-04,  1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 2500 Loss: 3.181014278652583e-07 Final Loss: 2.750007152557373
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([0.0012, 0.0010, 1.0001], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 2600 Loss: 5.892250101169338e-07 Final Loss: 2.9996814727783203
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0003, 1.9999, 0.9998], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 2700 Loss: 5.5875398174976e-07 Final Loss: 3.249572992324829
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-8.5346e-06, -1.2708e-03,  1.0001e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 2800 Loss: 2.683490265553701e-07 Final Loss: 3.3750319480895996
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-0.0040, -0.0022,  0.9995], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 2900 Loss: 4.953260031470563e-06 Final Loss: 2.6261868476867676
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0008, -1.9985,  1.0013], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 3000 Loss: 2.439974923618138e-05 Final Loss: 2.872288942337036
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 1.9997, -2.0000,  1.0001], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 3100 Loss: 4.0972753367896075e-07 Final Loss: 3.5627975463867188
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0001, 2.0000, 1.0002], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 3200 Loss: 2.642499339344795e-07 Final Loss: 3.124783754348755
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([-1.4572e-04,  1.0961e-03,  9.9997e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 3300 Loss: 1.7976360311422468e-07 Final Loss: 2.7499380111694336
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([ 3.6517e-03, -2.5856e-04,  1.0004e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 3400 Loss: 2.8139891128375893e-06 Final Loss: 2.6242640018463135
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-0.0230, -0.0070,  0.9923], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 3500 Loss: 6.074284465285018e-05 Final Loss: 3.1870627403259277
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 1.9999, -2.0001,  0.9996], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 3600 Loss: 4.1403072259527107e-07 Final Loss: 3.188039779663086
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([1.9999, 2.0001, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 3700 Loss: 1.720107434266538e-07 Final Loss: 3.624955654144287
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([2.9925e-04, 6.4547e-04, 1.0003e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 3800 Loss: 1.6457333629205095e-07 Final Loss: 2.874955654144287
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0001], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 3900 Loss: 9.951664736718158e-08 Final Loss: 3.499908447265625
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 4000 Loss: 9.99859821604332e-08 Final Loss: 2.6250901222229004
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0001, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 4100 Loss: 7.479703612034427e-08 Final Loss: 2.4375853538513184
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([3.2001e-04, 6.3572e-04, 9.9994e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 4200 Loss: 5.680031733845681e-08 Final Loss: 3.2499403953552246
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([2.4946e-04, 5.8638e-04, 9.9994e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 4300 Loss: 6.003885744121362e-08 Final Loss: 2.8748834133148193
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0044, 1.9955, 0.9955], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 4400 Loss: 0.00013982992095407099 Final Loss: 3.1106929779052734
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 1.9995, -2.0001,  0.9999], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 4500 Loss: 1.839895844568673e-07 Final Loss: 3.312570571899414
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 4600 Loss: 4.131982223043451e-08 Final Loss: 2.6248936653137207
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 0.9999], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 4700 Loss: 3.523442160258128e-08 Final Loss: 2.9375362396240234
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([ 2.9564e-04, -3.0906e-04,  1.0001e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 4800 Loss: 3.865696740490421e-08 Final Loss: 3.06248140335083
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([-0.0309, -0.0069,  1.0009], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 4900 Loss: 0.00015955556591507047 Final Loss: 2.8246536254882812
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([-0.0032,  0.0104,  0.9987], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 5000 Loss: 2.204057454946451e-05 Final Loss: 2.935544490814209
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0006, -1.9991,  1.0003], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 5100 Loss: 3.0710366445418913e-06 Final Loss: 3.18662691116333
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([1.9996, 2.0011, 0.9996], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 5200 Loss: 9.850859896687325e-07 Final Loss: 2.93727970123291
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([-1.6898e-04,  2.0894e-03,  9.9972e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 5300 Loss: 5.249573860055534e-07 Final Loss: 2.812276601791382
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([-3.4399e-04, -9.1799e-04,  1.0004e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 5400 Loss: 2.978373458972783e-07 Final Loss: 2.6250808238983154
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0001, 1.0002], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 5500 Loss: 1.860357770055998e-07 Final Loss: 2.8748064041137695
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0001], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 5600 Loss: 1.0996841837140892e-07 Final Loss: 2.500019073486328
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 5700 Loss: 6.477597480625263e-08 Final Loss: 2.874866008758545
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([-3.2796e-04,  3.1198e-04,  9.9986e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 5800 Loss: 4.316812507454415e-08 Final Loss: 3.3126797676086426
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 5900 Loss: 1.6639436495324844e-08 Final Loss: 2.937451124191284
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([5.0373e-05, 2.2280e-04, 9.9995e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 6000 Loss: 9.340306306171442e-09 Final Loss: 3.0624818801879883
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 6100 Loss: 1.642113645061727e-08 Final Loss: 3.062350273132324
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  0.9999], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 6200 Loss: 1.3942006660272455e-08 Final Loss: 2.9375877380371094
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([1.1406e-04, 1.2730e-04, 1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 6300 Loss: 2.697866818834882e-09 Final Loss: 3.0624563694000244
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0042, -2.0030,  1.0097], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 6400 Loss: 0.00010156959615414962 Final Loss: 3.30112886428833
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0002, 0.9998], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 6500 Loss: 1.0000329098147631e-07 Final Loss: 3.2497384548187256
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 6600 Loss: 2.9276225887997498e-09 Final Loss: 2.9375386238098145
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([ 2.5086e-05, -7.8626e-05,  1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 6700 Loss: 1.2576641950090561e-09 Final Loss: 3.124983787536621
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 6800 Loss: 5.002462888370474e-10 Final Loss: 3.1875052452087402
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([-2.5395e-05,  2.1577e-05,  9.9999e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 6900 Loss: 2.7425081650100935e-10 Final Loss: 2.6875
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 7000 Loss: 9.960808566855661e-11 Final Loss: 2.750007152557373
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 7100 Loss: 4.2022295365651274e-11 Final Loss: 2.937497854232788
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([3.1494e-05, 5.8562e-06, 1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 7200 Loss: 8.612246332750928e-11 Final Loss: 3.125
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([1.2011e-03, 4.8229e-04, 1.0001e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 7300 Loss: 2.084520218659236e-07 Final Loss: 2.749513864517212
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 1.9997, -2.0004,  0.9997], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 7400 Loss: 5.204052513363422e-07 Final Loss: 2.687715768814087
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0007, 2.0000, 0.9993], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 7500 Loss: 1.4296477957032039e-06 Final Loss: 3.187458038330078
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([-5.8825e-04, -3.0390e-04,  9.9989e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 7600 Loss: 4.30579802923603e-08 Final Loss: 2.937767744064331
batch  tensor([1, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 7700 Loss: 9.360696662241708e-10 Final Loss: 2.8124985694885254
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([ 1.4402e-05, -2.9065e-05,  1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 7800 Loss: 3.384368341130539e-10 Final Loss: 3.0000014305114746
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 7900 Loss: 1.3004468335520158e-10 Final Loss: 2.937502384185791
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([-6.5900e-06, -1.0349e-05,  1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 8000 Loss: 5.207460504474959e-11 Final Loss: 2.8124992847442627
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([ 9.4995e-07, -4.0084e-06,  1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 8100 Loss: 8.60093593568756e-12 Final Loss: 3.1250007152557373
batch  tensor([0, 0, 0], device='cuda:0')  output_vals  tensor([-1.6008e-04, -1.0271e-04,  9.9993e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 8200 Loss: 6.91140211728225e-09 Final Loss: 2.8126049041748047
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([0.0193, 0.0092, 1.0019], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 8300 Loss: 7.712279330007732e-05 Final Loss: 2.86175274848938
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  0.9999], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 8400 Loss: 8.407663898424289e-08 Final Loss: 2.5003843307495117
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([1.2666e-05, 2.3693e-05, 9.9999e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 8500 Loss: 1.1850387338085966e-10 Final Loss: 2.5624895095825195
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 8600 Loss: 2.9094024064924007e-11 Final Loss: 3.250002861022949
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 8700 Loss: 4.9592462081360367e-11 Final Loss: 3.187488079071045
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 8800 Loss: 1.2046197372939105e-10 Final Loss: 3.125011920928955
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([2.4537e-04, 1.3698e-04, 9.9999e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 8900 Loss: 1.4333584985593006e-08 Final Loss: 3.1248340606689453
batch  tensor([0, 0, 1], device='cuda:0')  output_vals  tensor([9.3351e-04, 3.8616e-04, 1.0016e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 9000 Loss: 1.3718912441618158e-06 Final Loss: 3.1232922077178955
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([2.0000, 2.0000, 1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([2., 2., 1.], device='cuda:0')
Step 9100 Loss: 3.4868015141853448e-09 Final Loss: 3.2500672340393066
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([1.8716e-05, 3.1859e-05, 9.9996e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 9200 Loss: 3.1418527779436545e-09 Final Loss: 3.1874704360961914
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 9300 Loss: 2.0103108067104358e-10 Final Loss: 3.437500476837158
batch  tensor([0, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 9400 Loss: 4.264234451656357e-11 Final Loss: 3.5625102519989014
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([ 0.0245, -0.0011,  0.9806], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 9500 Loss: 0.00023484387202188373 Final Loss: 2.9316844940185547
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([-4.2072e-04, -7.9684e-05,  9.9995e-01], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 9600 Loss: 7.75984787537709e-08 Final Loss: 2.875429630279541
batch  tensor([1, 1, 0], device='cuda:0')  output_vals  tensor([ 2.0000, -2.0000,  1.0000], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 2., -2.,  1.], device='cuda:0')
Step 9700 Loss: 4.748354487382755e-10 Final Loss: 3.187490940093994
batch  tensor([1, 0, 1], device='cuda:0')  output_vals  tensor([ 3.1777e-06, -6.9886e-06,  1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 9800 Loss: 5.946022146874341e-11 Final Loss: 2.8124959468841553
batch  tensor([1, 0, 0], device='cuda:0')  output_vals  tensor([1.1921e-07, 5.6550e-06, 1.0000e+00], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 1.], device='cuda:0')
Step 9900 Loss: 9.92726907622643e-12 Final Loss: 3.0000007152557373
