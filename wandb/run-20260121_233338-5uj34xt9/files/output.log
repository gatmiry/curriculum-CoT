[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
                                                                                                                                         
{'loss': 4.4082, 'grad_norm': 141.0, 'learning_rate': 0.0, 'epoch': 0.01}
{'loss': 4.3819, 'grad_norm': 140.0, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}
{'loss': 4.254, 'grad_norm': 138.0, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}
{'loss': 3.7953, 'grad_norm': 127.5, 'learning_rate': 1.2e-05, 'epoch': 0.04}
{'loss': 3.2788, 'grad_norm': 128.0, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.05}
{'loss': 2.1697, 'grad_norm': 121.5, 'learning_rate': 2e-05, 'epoch': 0.06}
{'loss': 1.5026, 'grad_norm': 67.0, 'learning_rate': 1.978494623655914e-05, 'epoch': 0.07}
{'loss': 1.0454, 'grad_norm': 52.75, 'learning_rate': 1.956989247311828e-05, 'epoch': 0.08}
{'loss': 0.7355, 'grad_norm': 35.5, 'learning_rate': 1.935483870967742e-05, 'epoch': 0.09}
{'loss': 0.5515, 'grad_norm': 24.375, 'learning_rate': 1.913978494623656e-05, 'epoch': 0.1}
{'loss': 0.4236, 'grad_norm': 15.75, 'learning_rate': 1.89247311827957e-05, 'epoch': 0.11}
{'loss': 0.3523, 'grad_norm': 8.5, 'learning_rate': 1.870967741935484e-05, 'epoch': 0.12}
{'loss': 0.3123, 'grad_norm': 4.1875, 'learning_rate': 1.849462365591398e-05, 'epoch': 0.13}
{'loss': 0.3036, 'grad_norm': 4.28125, 'learning_rate': 1.827956989247312e-05, 'epoch': 0.14}
{'loss': 0.3001, 'grad_norm': 4.46875, 'learning_rate': 1.806451612903226e-05, 'epoch': 0.15}
{'loss': 0.2902, 'grad_norm': 3.5625, 'learning_rate': 1.78494623655914e-05, 'epoch': 0.16}
{'loss': 0.2958, 'grad_norm': 4.28125, 'learning_rate': 1.763440860215054e-05, 'epoch': 0.17}
{'loss': 0.2916, 'grad_norm': 2.625, 'learning_rate': 1.741935483870968e-05, 'epoch': 0.18}
{'loss': 0.2894, 'grad_norm': 1.65625, 'learning_rate': 1.7204301075268818e-05, 'epoch': 0.19}
{'loss': 0.2929, 'grad_norm': 3.765625, 'learning_rate': 1.6989247311827958e-05, 'epoch': 0.2}
{'loss': 0.2935, 'grad_norm': 2.3125, 'learning_rate': 1.6774193548387098e-05, 'epoch': 0.21}
{'loss': 0.2813, 'grad_norm': 1.65625, 'learning_rate': 1.6559139784946237e-05, 'epoch': 0.22}
{'loss': 0.2861, 'grad_norm': 1.390625, 'learning_rate': 1.6344086021505377e-05, 'epoch': 0.23}
{'loss': 0.2828, 'grad_norm': 1.4609375, 'learning_rate': 1.6129032258064517e-05, 'epoch': 0.24}
{'loss': 0.2831, 'grad_norm': 1.8671875, 'learning_rate': 1.5913978494623657e-05, 'epoch': 0.26}
{'loss': 0.2815, 'grad_norm': 1.125, 'learning_rate': 1.5698924731182796e-05, 'epoch': 0.27}
{'loss': 0.2872, 'grad_norm': 2.5, 'learning_rate': 1.5483870967741936e-05, 'epoch': 0.28}
{'loss': 0.2868, 'grad_norm': 1.296875, 'learning_rate': 1.5268817204301076e-05, 'epoch': 0.29}
{'loss': 0.2874, 'grad_norm': 5.25, 'learning_rate': 1.5053763440860215e-05, 'epoch': 0.3}
{'loss': 0.2969, 'grad_norm': 1.609375, 'learning_rate': 1.4838709677419357e-05, 'epoch': 0.31}
{'loss': 0.2865, 'grad_norm': 2.5, 'learning_rate': 1.4623655913978497e-05, 'epoch': 0.32}
{'loss': 0.2866, 'grad_norm': 1.984375, 'learning_rate': 1.4408602150537636e-05, 'epoch': 0.33}
{'loss': 0.285, 'grad_norm': 2.046875, 'learning_rate': 1.4193548387096776e-05, 'epoch': 0.34}
{'loss': 0.2862, 'grad_norm': 3.390625, 'learning_rate': 1.3978494623655916e-05, 'epoch': 0.35}
{'loss': 0.2893, 'grad_norm': 4.125, 'learning_rate': 1.3763440860215056e-05, 'epoch': 0.36}
{'loss': 0.2847, 'grad_norm': 1.3125, 'learning_rate': 1.3548387096774194e-05, 'epoch': 0.37}
{'loss': 0.2827, 'grad_norm': 1.2109375, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.38}
{'loss': 0.2832, 'grad_norm': 1.8828125, 'learning_rate': 1.3118279569892473e-05, 'epoch': 0.39}
{'loss': 0.2873, 'grad_norm': 1.8515625, 'learning_rate': 1.2903225806451613e-05, 'epoch': 0.4}
{'loss': 0.2852, 'grad_norm': 1.25, 'learning_rate': 1.2688172043010754e-05, 'epoch': 0.41}
{'loss': 0.2873, 'grad_norm': 1.9140625, 'learning_rate': 1.2473118279569894e-05, 'epoch': 0.42}
{'loss': 0.2807, 'grad_norm': 1.4609375, 'learning_rate': 1.2258064516129034e-05, 'epoch': 0.43}
{'loss': 0.2821, 'grad_norm': 1.890625, 'learning_rate': 1.2043010752688173e-05, 'epoch': 0.44}
{'loss': 0.2832, 'grad_norm': 1.2265625, 'learning_rate': 1.1827956989247313e-05, 'epoch': 0.45}
{'loss': 0.2856, 'grad_norm': 1.0546875, 'learning_rate': 1.1612903225806453e-05, 'epoch': 0.46}
{'loss': 0.2804, 'grad_norm': 2.421875, 'learning_rate': 1.1397849462365593e-05, 'epoch': 0.47}
{'loss': 0.2829, 'grad_norm': 2.0, 'learning_rate': 1.118279569892473e-05, 'epoch': 0.48}
{'loss': 0.2813, 'grad_norm': 0.984375, 'learning_rate': 1.096774193548387e-05, 'epoch': 0.49}
{'loss': 0.2865, 'grad_norm': 2.171875, 'learning_rate': 1.0752688172043012e-05, 'epoch': 0.5}
{'loss': 0.2842, 'grad_norm': 2.28125, 'learning_rate': 1.0537634408602151e-05, 'epoch': 0.51}
{'loss': 0.2854, 'grad_norm': 2.53125, 'learning_rate': 1.0322580645161291e-05, 'epoch': 0.52}
{'loss': 0.2811, 'grad_norm': 1.25, 'learning_rate': 1.0107526881720431e-05, 'epoch': 0.53}
{'loss': 0.2812, 'grad_norm': 1.09375, 'learning_rate': 9.89247311827957e-06, 'epoch': 0.54}
{'loss': 0.2832, 'grad_norm': 1.421875, 'learning_rate': 9.67741935483871e-06, 'epoch': 0.55}
{'loss': 0.2827, 'grad_norm': 1.71875, 'learning_rate': 9.46236559139785e-06, 'epoch': 0.56}
{'loss': 0.28, 'grad_norm': 1.8203125, 'learning_rate': 9.24731182795699e-06, 'epoch': 0.57}
{'loss': 0.285, 'grad_norm': 1.0859375, 'learning_rate': 9.03225806451613e-06, 'epoch': 0.58}
{'loss': 0.2839, 'grad_norm': 1.75, 'learning_rate': 8.81720430107527e-06, 'epoch': 0.59}
{'loss': 0.2777, 'grad_norm': 3.015625, 'learning_rate': 8.602150537634409e-06, 'epoch': 0.6}
{'loss': 0.2853, 'grad_norm': 2.453125, 'learning_rate': 8.387096774193549e-06, 'epoch': 0.61}
{'loss': 0.2841, 'grad_norm': 0.984375, 'learning_rate': 8.172043010752689e-06, 'epoch': 0.62}
{'loss': 0.2871, 'grad_norm': 1.40625, 'learning_rate': 7.956989247311828e-06, 'epoch': 0.63}
{'loss': 0.2836, 'grad_norm': 0.97265625, 'learning_rate': 7.741935483870968e-06, 'epoch': 0.64}
{'loss': 0.28, 'grad_norm': 0.94921875, 'learning_rate': 7.526881720430108e-06, 'epoch': 0.65}
{'loss': 0.2846, 'grad_norm': 1.4375, 'learning_rate': 7.311827956989248e-06, 'epoch': 0.66}
{'loss': 0.2828, 'grad_norm': 1.15625, 'learning_rate': 7.096774193548388e-06, 'epoch': 0.67}
{'loss': 0.2816, 'grad_norm': 1.8984375, 'learning_rate': 6.881720430107528e-06, 'epoch': 0.68}
{'loss': 0.2817, 'grad_norm': 1.53125, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.69}
{'loss': 0.2783, 'grad_norm': 1.3203125, 'learning_rate': 6.451612903225806e-06, 'epoch': 0.7}
{'loss': 0.2807, 'grad_norm': 1.1328125, 'learning_rate': 6.236559139784947e-06, 'epoch': 0.71}
{'loss': 0.2849, 'grad_norm': 1.0390625, 'learning_rate': 6.021505376344087e-06, 'epoch': 0.72}
{'loss': 0.2844, 'grad_norm': 1.6484375, 'learning_rate': 5.806451612903226e-06, 'epoch': 0.73}
{'loss': 0.2871, 'grad_norm': 1.1875, 'learning_rate': 5.591397849462365e-06, 'epoch': 0.74}
{'loss': 0.2821, 'grad_norm': 1.640625, 'learning_rate': 5.376344086021506e-06, 'epoch': 0.76}
{'loss': 0.2789, 'grad_norm': 2.03125, 'learning_rate': 5.161290322580646e-06, 'epoch': 0.77}
{'loss': 0.2836, 'grad_norm': 1.5546875, 'learning_rate': 4.946236559139785e-06, 'epoch': 0.78}
{'loss': 0.2819, 'grad_norm': 1.25, 'learning_rate': 4.731182795698925e-06, 'epoch': 0.79}
{'loss': 0.2827, 'grad_norm': 1.9375, 'learning_rate': 4.516129032258065e-06, 'epoch': 0.8}
{'loss': 0.2828, 'grad_norm': 0.98046875, 'learning_rate': 4.3010752688172045e-06, 'epoch': 0.81}
{'loss': 0.2833, 'grad_norm': 1.328125, 'learning_rate': 4.086021505376344e-06, 'epoch': 0.82}
{'loss': 0.2802, 'grad_norm': 1.3515625, 'learning_rate': 3.870967741935484e-06, 'epoch': 0.83}
{'loss': 0.2849, 'grad_norm': 0.93359375, 'learning_rate': 3.655913978494624e-06, 'epoch': 0.84}
{'loss': 0.2799, 'grad_norm': 1.9140625, 'learning_rate': 3.440860215053764e-06, 'epoch': 0.85}
{'loss': 0.2805, 'grad_norm': 2.859375, 'learning_rate': 3.225806451612903e-06, 'epoch': 0.86}
{'loss': 0.2804, 'grad_norm': 1.59375, 'learning_rate': 3.0107526881720433e-06, 'epoch': 0.87}
{'loss': 0.2844, 'grad_norm': 1.1875, 'learning_rate': 2.7956989247311827e-06, 'epoch': 0.88}
{'loss': 0.2818, 'grad_norm': 0.9375, 'learning_rate': 2.580645161290323e-06, 'epoch': 0.89}
{'loss': 0.2859, 'grad_norm': 1.3828125, 'learning_rate': 2.3655913978494625e-06, 'epoch': 0.9}
{'loss': 0.2809, 'grad_norm': 1.5234375, 'learning_rate': 2.1505376344086023e-06, 'epoch': 0.91}
{'loss': 0.2866, 'grad_norm': 1.0859375, 'learning_rate': 1.935483870967742e-06, 'epoch': 0.92}
{'loss': 0.2819, 'grad_norm': 1.0625, 'learning_rate': 1.720430107526882e-06, 'epoch': 0.93}
{'loss': 0.283, 'grad_norm': 1.3515625, 'learning_rate': 1.5053763440860217e-06, 'epoch': 0.94}
{'loss': 0.2783, 'grad_norm': 1.3203125, 'learning_rate': 1.2903225806451614e-06, 'epoch': 0.95}
{'loss': 0.284, 'grad_norm': 1.2109375, 'learning_rate': 1.0752688172043011e-06, 'epoch': 0.96}
{'loss': 0.2796, 'grad_norm': 1.5625, 'learning_rate': 8.60215053763441e-07, 'epoch': 0.97}
{'loss': 0.2835, 'grad_norm': 0.9921875, 'learning_rate': 6.451612903225807e-07, 'epoch': 0.98}
{'loss': 0.2794, 'grad_norm': 1.8046875, 'learning_rate': 4.301075268817205e-07, 'epoch': 0.99}
{'loss': 0.2876, 'grad_norm': 2.359375, 'learning_rate': 2.1505376344086024e-07, 'epoch': 1.0}
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:28<00:00,  3.47it/s]
                                                                                                                                         
{'eval_loss': 0.2785240411758423, 'eval_runtime': 1.5056, 'eval_samples_per_second': 332.099, 'eval_steps_per_second': 10.627, 'epoch': 1.0}
{'train_runtime': 30.1121, 'train_samples_per_second': 3320.919, 'train_steps_per_second': 3.255, 'train_loss': 0.5244564848894976, 'epoch': 1.0}
