================================================================================
Using device: cuda
samples type in get_batch is torch.int64
bacth type before return is torch.int64
batch type is torch.int64
shape of self.transformer.wte(idx) torch.Size([128, 12, 64])  shape of cts_tokens torch.Size([128, 36])
Error executing job with overrides: []
Traceback (most recent call last):
  File "/accounts/projects/peter/gatmiry/distributional-CoT/train.py", line 47, in main
    train.fit()
    ~~~~~~~~~^^
  File "/accounts/projects/peter/gatmiry/distributional-CoT/test_composite_function.py", line 63, in fit
    output_vals, loss = model(batch, cot_outputs)
                        ~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/accounts/projects/peter/gatmiry/distributional-CoT/model.py", line 100, in forward
    x = pe_vecs + torch.cat([self.transformer.wte(idx), cts_tokens], dim=1)
                  ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
