batch  tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.0671, -0.0366, -0.0034, -0.0232, -0.0131, -0.0077, -0.0437,  0.0368,
        -0.0746,  0.0636, -0.2740,  0.0755, -0.0223, -0.0920, -0.0672, -0.0435,
        -0.0092,  0.0249, -0.0064,  0.0277], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  1.5000,  1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 0 Loss: 1.293653130531311 Final Loss: 1.293653130531311
batch  tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1249, -0.3131, -0.6387,  0.4018,  0.6888,  0.5787,  0.6000,  0.6490,
         0.2908,  0.4001,  0.2038,  0.5636,  0.6426,  0.6205,  0.6389,  0.6045,
         0.6845,  0.6485,  0.6615,  0.8171], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 100 Loss: 0.3127270042896271 Final Loss: 0.3127270042896271
batch  tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1262, -0.2830, -0.3514,  0.6782,  0.7969, -0.2882, -0.5795, -0.4496,
        -0.7707, -0.6583, -0.8248, -0.7728, -0.3488, -0.4485, -0.5960, -0.3947,
        -0.5381, -0.2589, -0.4075, -0.5584], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000,  1.5000,  1.5000, -0.5000, -0.5000, -0.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 200 Loss: 0.057353485375642776 Final Loss: 0.057353485375642776
batch  tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1381, -0.2564, -0.6945,  0.3037,  0.2606, -0.6036, -0.8575, -0.7019,
        -0.8130, -0.6361, -0.8124, -0.7609, -0.7503, -0.8156, -0.9015, -0.8182,
        -0.9237, -0.6665, -0.8560, -1.2052], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  0.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 300 Loss: 0.03979194164276123 Final Loss: 0.03979194164276123
batch  tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1213,  0.5773,  0.2935,  0.3204,  0.7762,  0.5676,  0.6323,  0.7192,
         0.2074,  0.2914,  0.0985, -0.1376, -0.6517, -0.7499, -0.8433, -0.7592,
        -0.8724, -0.6216, -0.8243, -1.2443], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 400 Loss: 0.04322265833616257 Final Loss: 0.04322265833616257
batch  tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1167,  0.5931,  0.3016,  0.3293,  0.2955,  0.2527, -0.5373, -0.3651,
        -0.4197, -0.2662, -0.4729,  0.5091,  0.7172,  0.6388,  0.6951,  0.7309,
         0.8521,  0.7401,  0.8576,  1.2914], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  0.5000,  0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 500 Loss: 0.019841987639665604 Final Loss: 0.019841987639665604
batch  tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1150,  0.6084,  0.3092,  0.3378,  0.8105,  0.5971,  0.6611,  0.7505,
         0.2234,  0.3066,  0.1137, -0.1226, -0.6763, -0.7734, -0.8845, -0.7953,
        -0.9123, -0.6453, -0.8612, -1.3064], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 600 Loss: 0.02207465097308159 Final Loss: 0.02207465097308159
batch  tensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1332,  0.6081,  0.6462, -0.2514, -0.3800, -0.2614,  0.0692,  0.2595,
         0.1902,  0.2762,  0.0838, -0.1630, -0.7467, -0.8296, -0.9414, -0.8570,
        -0.9766, -0.6893, -0.9059, -1.3469], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 700 Loss: 0.010617440566420555 Final Loss: 0.010617440566420555
batch  tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1240,  0.6331,  0.3192, -0.6716, -0.7778, -0.6525, -0.9528, -0.7703,
        -0.4732, -0.3151, -0.5161,  0.5224,  0.3552,  0.2444,  0.1216,  0.3003,
         0.2770,  0.3291,  0.4863,  0.5081], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 800 Loss: 0.00928141176700592 Final Loss: 0.00928141176700592
batch  tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1227, -0.2588, -0.7471,  0.3363,  0.2970,  0.2548,  0.0727,  0.2635,
         0.1934,  0.2818,  0.0863, -0.1727, -0.2978, -0.3960, -0.5921, -0.3701,
        -0.5569, -0.2394, -0.3563, -0.5114], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 900 Loss: 0.004485138691961765 Final Loss: 0.004485138691961765
batch  tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1384, -0.2709, -0.3123, -0.2814, -0.4180, -0.2914, -0.6200, -0.4232,
        -0.9045, -0.7026, -0.9011, -0.8364, -0.8398, -0.9068, -1.0312, -0.9429,
        -1.0621, -0.7662, -0.9815, -1.4077], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 1000 Loss: 0.0034966457169502974 Final Loss: 0.0034966457169502974
batch  tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1256, -0.2679, -0.3085, -0.2747, -0.8289, -0.6999, -1.0047, -0.8174,
        -0.5011, -0.3379, -0.5353,  0.5446,  0.3720,  0.2582,  0.1339,  0.3154,
         0.2876,  0.3416,  0.5062,  0.5098], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 1100 Loss: 0.0019499908667057753 Final Loss: 0.0019499908667057753
batch  tensor([1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1387,  0.6603,  0.3268, -0.7188, -0.8353, -0.7035,  0.6781,  0.7667,
         0.6970,  0.7228,  0.6317, -0.7895, -0.8074, -0.8866, -1.0198, -0.9260,
        -1.0556, -0.7492, -0.9766, -1.4452], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000, -1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 1200 Loss: 0.001398010179400444 Final Loss: 0.001398010179400444
batch  tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1333, -0.2751, -0.7902, -0.7518, -0.4320, -0.3093, -0.6438, -0.4503,
        -0.9374, -0.7365, -0.9294, -0.8653, -0.8705, -0.9375, -1.0724, -0.9782,
        -1.0991, -0.8005, -1.0219, -1.4538], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 1300 Loss: 0.001111518358811736 Final Loss: 0.001111518358811736
batch  tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1434, -0.2845, -0.8037, -0.7641, -0.8837, -0.7458, -1.0459, -0.8539,
        -0.9689, -0.7633, -0.9479,  0.8792,  0.7942,  0.7148,  0.7869,  0.8307,
         0.9664,  0.8296,  0.9681,  1.4575], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 1400 Loss: 0.0006074925186112523 Final Loss: 0.0006074925186112523
batch  tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1264, -0.2779, -0.3158, -0.2814, -0.8539, -0.7244,  0.6920,  0.7833,
         0.2051,  0.2910,  0.1010,  0.5870,  0.8457,  0.7632,  0.8315,  0.8681,
         0.9979,  0.8648,  1.0046,  1.4762], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -1.5000, -1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 1500 Loss: 0.0003866866172757 Final Loss: 0.0003866866172757
batch  tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1207,  0.6968,  0.7293,  0.8020,  0.3484, -0.6830,  0.7456,  0.8281,
         0.7399,  0.7685,  0.6825,  0.9675,  0.4563,  0.3356,  0.2150,  0.3793,
         0.3557,  0.3968,  0.5658,  0.5086], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000,  1.5000,  0.5000, -1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 1600 Loss: 0.00020551183843053877 Final Loss: 0.00020551183843053877
batch  tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1464, -0.2887, -0.3284, -0.2968, -0.4365, -0.3128, -0.6514, -0.4494,
        -0.5152, -0.3419, -0.5454,  0.5775,  0.8243,  0.7465,  0.8191,  0.8629,
         0.9975,  0.8544,  0.9940,  1.4809], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 1700 Loss: 9.774186764843762e-05 Final Loss: 9.774186764843762e-05
batch  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1279,  0.7018,  0.3465,  0.3796,  0.9276, -0.2771,  0.1028,  0.2956,
         0.7315,  0.7635,  0.6760, -0.7799, -0.2878, -0.3885, -0.6067, -0.3669,
        -0.5681, -0.2404, -0.3536, -0.4994], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  1.5000, -0.5000,  0.5000,  0.5000,  1.5000,
         1.5000,  1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 1800 Loss: 5.644542397931218e-05 Final Loss: 5.644542397931218e-05
batch  tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1220, -0.2786, -0.8006, -0.7631, -0.8799, -0.7456, -1.0587, -0.8693,
        -0.5260, -0.3613, -0.5535,  0.5668,  0.8230,  0.7415,  0.8155,  0.8564,
         0.9887,  0.8567,  1.0007,  1.4909], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 1900 Loss: 4.5899661927251145e-05 Final Loss: 4.5899661927251145e-05
batch  tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1385, -0.2854, -0.8153, -0.7743, -0.8951,  0.2535,  0.0516,  0.2495,
         0.7070,  0.7369,  0.6453, -0.8448, -0.8571, -0.9322, -1.0726, -0.9780,
        -1.1075, -0.7948, -1.0273, -1.4973], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -1.5000,  0.5000,  0.5000,  0.5000,  1.5000,
         1.5000,  1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 2000 Loss: 1.9474056898616254e-05 Final Loss: 1.9474056898616254e-05
batch  tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1341,  0.6991,  0.3462,  0.3795,  0.3361, -0.7044, -1.0274, -0.8301,
        -0.5036, -0.3339, -0.5330,  0.5899,  0.4133,  0.2955,  0.1713,  0.3459,
         0.3156,  0.3684,  0.5402,  0.4973], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  0.5000, -1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 2100 Loss: 1.9294731828267686e-05 Final Loss: 1.9294731828267686e-05
batch  tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1269, -0.2829, -0.8101, -0.7706, -0.4353, -0.3190, -0.6578, -0.4651,
        -0.9608, -0.7576, -0.9502,  0.9170,  0.4011,  0.2828,  0.1597,  0.3328,
         0.3029,  0.3598,  0.5342,  0.5053], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -1.5000,
        -1.5000, -1.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 2200 Loss: 9.98577343125362e-06 Final Loss: 9.98577343125362e-06
batch  tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1362, -0.2846, -0.8149, -0.7741, -0.4407, -0.3210, -0.6605, -0.4649,
        -0.5208, -0.3491, -0.5480, -0.2048, -0.3492, -0.4407, -0.6425, -0.4299,
        -0.6238, -0.2847, -0.4022, -0.4978], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 2300 Loss: 1.1951451597269624e-05 Final Loss: 1.1951451597269624e-05
batch  tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1275, -0.2842, -0.3231, -0.2881, -0.8713,  0.2633, -0.6463, -0.4566,
        -0.5098, -0.3406, -0.5375, -0.1970, -0.8715, -0.9421, -1.0846, -0.9945,
        -1.1171, -0.8078, -1.0389, -1.5002], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -1.5000,  0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 2400 Loss: 8.448440894426312e-06 Final Loss: 8.448440894426312e-06
batch  tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1301, -0.2855, -0.3252,  0.7847,  0.9270,  0.6777,  0.7479,  0.8274,
         0.7495,  0.7698,  0.6904, -0.7953, -0.2880, -0.3893, -0.6072, -0.3727,
        -0.5783, -0.2413, -0.3574, -0.4955], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 2500 Loss: 9.01310340850614e-06 Final Loss: 9.01310340850614e-06
batch  tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1406,  0.6905,  0.7296,  0.8030,  0.3355,  0.2850, -0.6324, -0.4289,
        -0.4906, -0.3179, -0.5234,  0.6077,  0.8696,  0.7900,  0.8616,  0.8923,
         1.0271,  0.8866,  1.0247,  1.5003], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000,  1.5000,  0.5000,  0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 2600 Loss: 7.00856344337808e-06 Final Loss: 7.00856344337808e-06
batch  tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1387,  0.6928,  0.7305, -0.2764, -0.4139,  0.6759,  0.7454,  0.8198,
         0.7488,  0.7649,  0.6897,  0.9860,  0.4673,  0.3413,  0.2240,  0.3823,
         0.3604,  0.4031,  0.5744,  0.5052], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -0.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 2700 Loss: 9.649758794694208e-06 Final Loss: 9.649758794694208e-06
batch  tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1323, -0.2823, -0.3223,  0.7838,  0.3321, -0.7184,  0.7285,  0.8093,
         0.2202,  0.3059,  0.1224,  0.6105,  0.8761,  0.7942,  0.8647,  0.8927,
         1.0260,  0.8896,  1.0313,  1.5008], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000,  1.5000,  0.5000, -1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 2800 Loss: 8.809089194983244e-06 Final Loss: 8.809089194983244e-06
batch  tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1339, -0.2868, -0.3293,  0.7783,  0.3239,  0.2728,  0.0776,  0.2718,
         0.2109,  0.2949,  0.1174, -0.1682, -0.3143, -0.4121, -0.6204, -0.4028,
        -0.6036, -0.2607, -0.3810, -0.5036], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 2900 Loss: 1.0281098184350412e-05 Final Loss: 1.0281098184350412e-05
batch  tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1243, -0.2829, -0.3231, -0.2861, -0.8650, -0.7358,  0.7049,  0.7941,
         0.7166,  0.7506,  0.6588, -0.8239, -0.3086, -0.4040, -0.6171, -0.3945,
        -0.5940, -0.2576, -0.3746, -0.5014], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 3000 Loss: 1.0259205737384036e-05 Final Loss: 1.0259205737384036e-05
batch  tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1340,  0.7018,  0.3456,  0.3801,  0.9353,  0.6859,  0.7601,  0.8346,
         0.7560,  0.7760,  0.7002, -0.7803, -0.2801, -0.3820, -0.6027, -0.3680,
        -0.5730, -0.2351, -0.3542, -0.5003], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 3100 Loss: 5.801181487186113e-06 Final Loss: 5.801181487186113e-06
batch  tensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1365,  0.7012,  0.7380, -0.2778, -0.4131,  0.6819,  0.7522,  0.8248,
         0.7532,  0.7703,  0.6942,  0.9894,  0.9127,  0.8303,  0.9000,  0.9169,
         1.0529,  0.9124,  1.0529,  1.4988], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -0.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 3200 Loss: 5.920836883888114e-06 Final Loss: 5.920836883888114e-06
batch  tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1317, -0.2849, -0.8174,  0.3681,  0.9253,  0.6764, -1.0336, -0.8401,
        -0.5053, -0.3322, -0.5287, -0.1909, -0.3341, -0.4275, -0.6347, -0.4189,
        -0.6148, -0.2751, -0.3963, -0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  1.5000,  1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 3300 Loss: 6.59630404697964e-06 Final Loss: 6.59630404697964e-06
batch  tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1301,  0.7100,  0.7419, -0.2724, -0.8548,  0.2810, -0.6393, -0.4442,
        -0.9380, -0.7319, -0.9347, -0.8685, -0.8781, -0.9489, -1.0939, -0.9980,
        -1.1217, -0.8136, -1.0445, -1.5005], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -1.5000,  0.5000, -0.5000, -0.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 3400 Loss: 3.724850557773607e-06 Final Loss: 3.724850557773607e-06
batch  tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1226, -0.2821, -0.8112,  0.3687,  0.3284, -0.7283,  0.7253,  0.8069,
         0.7289,  0.7605,  0.6707,  0.9708,  0.8933,  0.8098,  0.8803,  0.9012,
         1.0353,  0.9001,  1.0428,  1.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  0.5000, -1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 3500 Loss: 6.0658003349089995e-06 Final Loss: 6.0658003349089995e-06
batch  tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1305, -0.2828, -0.8142, -0.7744, -0.4343, -0.3205, -0.6562, -0.4675,
        -0.5185, -0.3463, -0.5408,  0.5889,  0.4090,  0.2938,  0.1726,  0.3390,
         0.3124,  0.3701,  0.5434,  0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 3600 Loss: 6.898520950926468e-06 Final Loss: 6.898520950926468e-06
batch  tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1238, -0.2832, -0.8150,  0.3684,  0.9241,  0.6755, -1.0312, -0.8381,
        -0.5033, -0.3304, -0.5254, -0.1892, -0.3329, -0.4255, -0.6322, -0.4190,
        -0.6140, -0.2738, -0.3960, -0.4997], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  1.5000,  1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 3700 Loss: 3.535600399118266e-06 Final Loss: 3.535600399118266e-06
batch  tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1229, -0.2825, -0.3254,  0.7921,  0.3366, -0.7221,  0.7363,  0.8148,
         0.7375,  0.7655,  0.6797,  0.9770,  0.9001,  0.8173,  0.8874,  0.9046,
         1.0412,  0.9045,  1.0482,  1.4995], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000,  1.5000,  0.5000, -1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 3800 Loss: 5.6463995861122385e-06 Final Loss: 5.6463995861122385e-06
batch  tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1317,  0.7042,  0.3444,  0.3810,  0.3408, -0.7067,  0.7432,  0.8185,
         0.7406,  0.7670,  0.6855,  0.9792,  0.4596,  0.3409,  0.2238,  0.3762,
         0.3580,  0.4026,  0.5734,  0.5031], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  0.5000, -1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 3900 Loss: 5.470684754982358e-06 Final Loss: 5.470684754982358e-06
batch  tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1232, -0.2841, -0.8181, -0.7784, -0.4352,  0.6633, -1.0556, -0.8613,
        -0.9661, -0.7597, -0.9472, -0.8909, -0.8946, -0.9625, -1.1068, -1.0125,
        -1.1339, -0.8302, -1.0554, -1.4981], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -0.5000,  1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 4000 Loss: 4.397095835884102e-06 Final Loss: 4.397095835884102e-06
batch  tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1185, -0.2817, -0.3238, -0.2860, -0.4092,  0.6671, -1.0392, -0.8466,
        -0.5060, -0.3359, -0.5260,  0.5956,  0.4156,  0.3049,  0.1837,  0.3477,
         0.3223,  0.3774,  0.5507,  0.5013], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -0.5000,  1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 4100 Loss: 1.772916789377632e-06 Final Loss: 1.772916789377632e-06
batch  tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1280,  0.7008,  0.7357, -0.2787, -0.8641,  0.2768,  0.0848,  0.2774,
         0.2173,  0.3042,  0.1291,  0.6223,  0.8814,  0.8036,  0.8709,  0.8971,
         1.0345,  0.8919,  1.0337,  1.5005], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -1.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 4200 Loss: 3.5593566281022504e-06 Final Loss: 3.5593566281022504e-06
batch  tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1223,  0.7108,  0.3503,  0.3860,  0.9419, -0.2871, -0.6278, -0.4339,
        -0.4878, -0.3156, -0.5152,  0.6153,  0.4355,  0.3196,  0.2002,  0.3584,
         0.3358,  0.3879,  0.5607,  0.5019], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000,  0.5000,  1.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 4300 Loss: 3.214847083654604e-06 Final Loss: 3.214847083654604e-06
batch  tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1336,  0.7022,  0.7370, -0.2781, -0.8607, -0.7319, -1.0462, -0.8489,
        -0.9612, -0.7500, -0.9438, -0.8889, -0.8908, -0.9578, -1.1006, -1.0109,
        -1.1330, -0.8235, -1.0473, -1.4979], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 4400 Loss: 3.4984200283361133e-06 Final Loss: 3.4984200283361133e-06
batch  tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1225, -0.2830, -0.8141,  0.3696,  0.3301,  0.2724,  0.0856,  0.2748,
         0.2136,  0.3056,  0.1246,  0.6147,  0.8752,  0.7974,  0.8644,  0.8910,
         1.0285,  0.8892,  1.0314,  1.5009], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 4500 Loss: 5.068350674264366e-06 Final Loss: 5.068350674264366e-06
batch  tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1208, -0.2806, -0.3243, -0.2875, -0.8690,  0.2659, -0.6405, -0.4566,
        -0.9489, -0.7441, -0.9366,  0.9333,  0.4124,  0.3003,  0.1800,  0.3407,
         0.3178,  0.3732,  0.5446,  0.5033], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -1.5000,  0.5000, -0.5000, -0.5000, -1.5000,
        -1.5000, -1.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 4600 Loss: 3.6589055980584817e-06 Final Loss: 3.6589055980584817e-06
batch  tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1256, -0.2836, -0.3294, -0.2947, -0.8808,  0.2662,  0.0735,  0.2639,
         0.2073,  0.2983,  0.1212,  0.6159,  0.4338,  0.3174,  0.1974,  0.3557,
         0.3331,  0.3866,  0.5571,  0.4984], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -1.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 4700 Loss: 3.3670403354335576e-06 Final Loss: 3.3670403354335576e-06
batch  tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1190,  0.7140,  0.3504, -0.7488, -0.8626,  0.2756,  0.0919,  0.2820,
         0.7286,  0.7639,  0.6780,  0.9762,  0.8961,  0.8143,  0.8828,  0.8986,
         1.0358,  0.8993,  1.0442,  1.4996], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000, -1.5000, -1.5000,  0.5000,  0.5000,  0.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 4800 Loss: 3.1408983431902016e-06 Final Loss: 3.1408983431902016e-06
batch  tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1201, -0.2816, -0.8134,  0.3725,  0.9294,  0.6782,  0.7505,  0.8262,
         0.7460,  0.7750,  0.6920,  0.9869,  0.4653,  0.3462,  0.2282,  0.3771,
         0.3597,  0.4065,  0.5815,  0.5001], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 4900 Loss: 3.7884699395362986e-06 Final Loss: 3.7884699395362986e-06
batch  tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1343,  0.7016,  0.7363, -0.2808, -0.4127, -0.3042,  0.0861,  0.2773,
         0.2179,  0.3062,  0.1320, -0.1656, -0.3156, -0.4102, -0.6175, -0.4079,
        -0.6063, -0.2590, -0.3848, -0.4985], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -0.5000, -0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 5000 Loss: 6.949804628675338e-06 Final Loss: 6.949804628675338e-06
batch  tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1279, -0.2810, -0.3255,  0.7908,  0.3401, -0.7215,  0.7377,  0.8151,
         0.2250,  0.3160,  0.1351, -0.1628, -0.8356, -0.9155, -1.0562, -0.9683,
        -1.0954, -0.7820, -1.0173, -1.5000], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000,  1.5000,  0.5000, -1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 5100 Loss: 3.1123997814574977e-06 Final Loss: 3.1123997814574977e-06
batch  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1194,  0.7119,  0.3495, -0.7500, -0.8637,  0.2754,  0.0925,  0.2811,
         0.2191,  0.3108,  0.1323,  0.6206,  0.4399,  0.3263,  0.2071,  0.3597,
         0.3409,  0.3913,  0.5632,  0.4989], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000, -1.5000, -1.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 5200 Loss: 3.4934862469526706e-06 Final Loss: 3.4934862469526706e-06
batch  tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1260, -0.2789, -0.8115,  0.3743,  0.3380, -0.7303, -1.0439, -0.8518,
        -0.5098, -0.3377, -0.5271, -0.1969, -0.8770, -0.9478, -1.0891, -1.0006,
        -1.1217, -0.8145, -1.0431, -1.5000], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  0.5000, -1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 5300 Loss: 4.812282440980198e-06 Final Loss: 4.812282440980198e-06
batch  tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1237,  0.7112,  0.7410,  0.8175,  0.9537, -0.2895,  0.1090,  0.3024,
         0.2345,  0.3232,  0.1478,  0.6335,  0.8994,  0.8216,  0.8903,  0.9053,
         1.0446,  0.9047,  1.0477,  1.5002], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000,  1.5000,  1.5000, -0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 5400 Loss: 2.040116669377312e-06 Final Loss: 2.040116669377312e-06
batch  tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1222,  0.7118,  0.3472, -0.7548, -0.4142,  0.6776, -1.0396, -0.8410,
        -0.9476, -0.7411, -0.9348, -0.8779, -0.3426, -0.4319, -0.6353, -0.4294,
        -0.6202, -0.2796, -0.4035, -0.5002], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000, -1.5000, -0.5000,  1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 5500 Loss: 1.7632215758567327e-06 Final Loss: 1.7632215758567327e-06
batch  tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1318,  0.7067,  0.7379,  0.8134,  0.3520, -0.7147, -1.0328, -0.8352,
        -0.9442, -0.7344, -0.9340, -0.8782, -0.3407, -0.4306, -0.6343, -0.4284,
        -0.6213, -0.2776, -0.4028, -0.4974], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000,  1.5000,  0.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 5600 Loss: 2.4205432964663487e-06 Final Loss: 2.4205432964663487e-06
batch  tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1176, -0.2788, -0.8097,  0.3751,  0.3413, -0.7299,  0.7368,  0.8133,
         0.2240,  0.3175,  0.1347,  0.6203,  0.8821,  0.8033,  0.8723,  0.8921,
         1.0312,  0.8940,  1.0385,  1.5000], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000,  0.5000,  0.5000, -1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 5700 Loss: 2.0249758563295472e-06 Final Loss: 2.0249758563295472e-06
batch  tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1278,  0.7141,  0.3486, -0.7554, -0.8674, -0.7371, -1.0508, -0.8571,
        -0.9597, -0.7566, -0.9439,  0.9387,  0.4173,  0.3057,  0.1876,  0.3409,
         0.3224,  0.3771,  0.5485,  0.4997], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000,  1.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 5800 Loss: 1.862964950305468e-06 Final Loss: 1.862964950305468e-06
batch  tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1235, -0.2807, -0.3282,  0.7920,  0.9335,  0.6822,  0.7566,  0.8277,
         0.7523,  0.7754,  0.6993,  0.9937,  0.9141,  0.8328,  0.8984,  0.9100,
         1.0516,  0.9109,  1.0550,  1.4988], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 5900 Loss: 4.541497219179291e-06 Final Loss: 4.541497219179291e-06
batch  tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1245,  0.7105,  0.7411,  0.8168,  0.9553,  0.7021, -1.0210, -0.8239,
        -0.4869, -0.3131, -0.5112, -0.1710, -0.3242, -0.4172, -0.6259, -0.4135,
        -0.6108, -0.2639, -0.3931, -0.4970], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000,  1.5000,  1.5000,  1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 6000 Loss: 2.6099644401256228e-06 Final Loss: 2.6099644401256228e-06
batch  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],
       device='cuda:0')  output_vals  tensor([-0.1224,  0.7133,  0.7434,  0.8202,  0.9569,  0.7038,  0.7837,  0.8488,
         0.7695,  0.7914,  0.7197,  1.0066,  0.9311,  0.8498,  0.9170,  0.9202,
         1.0633,  0.9235,  1.0656,  1.4966], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000], device='cuda:0')
Step 6100 Loss: 2.6825314307643566e-06 Final Loss: 2.6825314307643566e-06
batch  tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1246,  0.7096,  0.7409, -0.2838, -0.4130, -0.3080, -0.6420, -0.4448,
        -0.5030, -0.3263, -0.5228, -0.1833, -0.3360, -0.4273, -0.6298, -0.4270,
        -0.6212, -0.2733, -0.4008, -0.4999], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 6200 Loss: 1.3268352176964981e-06 Final Loss: 1.3268352176964981e-06
batch  tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1],
       device='cuda:0')  output_vals  tensor([-0.1261, -0.2796, -0.3274, -0.2930, -0.8744, -0.7489,  0.7275,  0.8062,
         0.2204,  0.3143,  0.1341,  0.6224,  0.4412,  0.3285,  0.2109,  0.3593,
         0.3436,  0.3944,  0.5690,  0.4999], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -0.5000, -0.5000, -1.5000, -1.5000,  1.5000,  1.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,  0.5000,
         0.5000,  0.5000,  0.5000,  0.5000], device='cuda:0')
Step 6300 Loss: 1.479326897424471e-06 Final Loss: 1.479326897424471e-06
batch  tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0],
       device='cuda:0')  output_vals  tensor([-0.1175,  0.7177,  0.7412, -0.2763, -0.3964, -0.3038,  0.1055,  0.2896,
         0.7380,  0.7730,  0.6884, -0.8227, -0.3069, -0.4005, -0.6129, -0.3949,
        -0.5937, -0.2511, -0.3787, -0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -0.5000, -0.5000,  0.5000,  0.5000,  1.5000,
         1.5000,  1.5000, -1.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -0.5000], device='cuda:0')
Step 6400 Loss: 2.9991451810928993e-06 Final Loss: 2.9991451810928993e-06
batch  tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1256,  0.7196,  0.7436, -0.2776, -0.8577, -0.7338, -1.0475, -0.8527,
        -0.5059, -0.3351, -0.5239,  0.6142,  0.8643,  0.7890,  0.8598,  0.8839,
         1.0240,  0.8845,  1.0279,  1.5002], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([ 1.5000,  1.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -0.5000,
        -0.5000, -0.5000,  0.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,
         1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')
Step 6500 Loss: 9.18325167731382e-06 Final Loss: 9.18325167731382e-06
batch  tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1311,  0.7148,  0.7455,  0.8214,  0.9607,  0.7064,  0.7872,  0.8488,
         0.7732,  0.7923,  0.7225,  1.0102,  0.9339,  0.8538,  0.9210,  0.9219,
         1.0669,  0.9252,  1.0681,  1.4975], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000], device='cuda:0')
Step 6600 Loss: 4.793967946170596e-06 Final Loss: 4.793967946170596e-06
batch  tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],
       device='cuda:0')  output_vals  tensor([-0.1264, -0.2803, -0.8184, -0.7856, -0.8920,  0.2663, -0.6487, -0.4678,
        -0.5128, -0.3426, -0.5320, -0.2023, -0.8879, -0.9583, -1.0958, -1.0066,
        -1.1280, -0.8214, -1.0525, -1.4994], device='cuda:0',
       grad_fn=<SliceBackward0>)  cot_outputs  tensor([-0.5000, -1.5000, -1.5000, -1.5000,  0.5000, -0.5000, -0.5000, -0.5000,
        -0.5000, -0.5000, -0.5000, -1.5000, -1.5000, -1.5000, -1.5000, -1.5000,
        -1.5000, -1.5000, -1.5000, -1.5000], device='cuda:0')
Step 6700 Loss: 2.1564990220213076e-06 Final Loss: 2.1564990220213076e-06
Traceback (most recent call last):
  File "/accounts/projects/peter/gatmiry/distributional-CoT/train.py", line 51, in <module>
    main()
    ~~~~^^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    ~~~~~~~~~~^
        args=args,
        ^^^^^^^^^^
    ...<3 lines>...
        config_name=config_name,
        ^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    ~~~~~~~~^
        run=args.run,
        ^^^^^^^^^^^^^
    ...<5 lines>...
        overrides=overrides,
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    ~~~~~~~~~~~~~~^
        lambda: hydra.run(
        ^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        )
        ^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ~~~~~~~~~^
        config_name=config_name,
        ^^^^^^^^^^^^^^^^^^^^^^^^
        task_function=task_function,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        overrides=overrides,
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
        hydra_context=HydraContext(
    ...<6 lines>...
        configure_logging=with_log_configuration,
    )
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ~~~~~~~~~~~~~^^^^^^^^^^
  File "/accounts/projects/peter/gatmiry/distributional-CoT/train.py", line 47, in main
    train.fit()
    ~~~~~~~~~^^
  File "/accounts/projects/peter/gatmiry/distributional-CoT/test_composite_function.py", line 79, in fit
    batch, cot_outputs = dataset.get_batch(batch_size=batch_size, flipping_subsets=flipping_subsets)
                         ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/accounts/projects/peter/gatmiry/distributional-CoT/test_composite_function.py", line 239, in get_batch
    result = self.target_function(cot_tmp_batch_flipping)
  File "/accounts/projects/peter/gatmiry/distributional-CoT/test_composite_function.py", line 197, in compute_function
    term_vals = term_vals * samples[:, var]
    ^^^^^^^^^
KeyboardInterrupt
