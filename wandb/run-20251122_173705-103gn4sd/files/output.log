================================================================================
Using device: cuda
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
batch  tensor([0, 1, 1], device='cuda:0')  output_vals  tensor([ 0.1620,  0.2120, -0.0235], device='cuda:0', grad_fn=<SliceBackward0>)  cot_outputs  tensor([0., 0., 0.], device='cuda:0')
Step 0 Loss: 0.023912539705634117 Final Loss: 0.04492827504873276
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1., -1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([1., 1., 1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([ 1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1.,  1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
cot_tmp_batch_flipping  tensor([-1., -1.,  1.], device='cuda:0')
Traceback (most recent call last):
  File "/accounts/projects/peter/gatmiry/distributional-CoT/train.py", line 51, in <module>
    main()
    ~~~~^^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    ~~~~~~~~~~^
        args=args,
        ^^^^^^^^^^
    ...<3 lines>...
        config_name=config_name,
        ^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    ~~~~~~~~^
        run=args.run,
        ^^^^^^^^^^^^^
    ...<5 lines>...
        overrides=overrides,
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    ~~~~~~~~~~~~~~^
        lambda: hydra.run(
        ^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        )
        ^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ~~~~~~~~~^
        config_name=config_name,
        ^^^^^^^^^^^^^^^^^^^^^^^^
        task_function=task_function,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        overrides=overrides,
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
        hydra_context=HydraContext(
    ...<6 lines>...
        configure_logging=with_log_configuration,
    )
  File "/accounts/projects/peter/gatmiry/.local/lib/python3.13/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ~~~~~~~~~~~~~^^^^^^^^^^
  File "/accounts/projects/peter/gatmiry/distributional-CoT/train.py", line 47, in main
    train.fit()
    ~~~~~~~~~^^
  File "/accounts/projects/peter/gatmiry/distributional-CoT/test_composite_function.py", line 64, in fit
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/usr/local/linux/miniforge-3.13/lib/python3.13/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
KeyboardInterrupt
